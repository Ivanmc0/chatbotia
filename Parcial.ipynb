{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sie4fiOb6x_V"
      },
      "source": [
        "#Parte 1: Conceptos de RAG\n",
        "Definición y Aplicación:\n",
        "\n",
        "Explica qué es el concepto de RAG (Retrieval-Augmented Generation) y cómo se diferencia de un chatbot generativo simple. Da un ejemplo práctico donde un chatbot RAG sería más útil que uno basado solo en generación.\n",
        "Preguntas de Selección Múltiple.\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WF6jh8k0xGJt"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1n6iOvFg67Wk"
      },
      "source": [
        "\n",
        "##Responde:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NKNl6kqw7DOy"
      },
      "source": [
        "Respuesta: RAG (Retrieval-Augmented Generation) es un enfoque en inteligencia artificial que combina la generación de texto con la recuperación de información. A diferencia de un chatbot generativo simple que crea respuestas solo a partir de los patrones aprendidos durante su entrenamiento, un modelo RAG primero recupera información relevante de una base de datos o fuente de conocimiento (por ejemplo, documentos, bases de datos, páginas web) y luego genera una respuesta utilizando tanto esa información como su capacidad de generación.\n",
        "\n",
        "Diferencias clave:\n",
        "Chatbot generativo simple: Solo se basa en el modelo entrenado para generar respuestas. Está limitado por lo que aprendió en el momento del entrenamiento.\n",
        "Chatbot RAG: Combina la generación con la recuperación de información externa, lo que le permite generar respuestas más actualizadas y específicas. El componente de recuperación busca datos relevantes para enriquecer la generación.\n",
        "Ejemplo práctico:\n",
        "Imagina un asistente de soporte técnico que ayuda a los empleados de una empresa. Un chatbot generativo simple puede ofrecer respuestas generales basadas en problemas comunes, pero puede quedarse corto si el empleado tiene un problema específico o reciente con un sistema que no estaba disponible durante el entrenamiento del modelo.\n",
        "\n",
        "Un chatbot RAG, en cambio, podría buscar en la base de conocimientos actualizada de la empresa o en la documentación técnica más reciente y ofrecer una solución precisa que involucra la versión exacta del software o sistema que el empleado está usando. Esto sería mucho más útil en casos donde la información cambia con frecuencia."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sH-DqU0K8Yc9"
      },
      "source": [
        "#Parte 2: Implementación de un Chatbot RAG\n",
        "Carga y Preparación del Dataset:\n",
        "\n",
        "Crea y sube un archivo CSV con preguntas frecuentes de un centro educativo llamado Unicuces. El archivo debe contener dos columnas: Pregunta y Respuesta.\n",
        "Usa pandas para cargar el archivo y convertirlo en un diccionario de preguntas y respuestas.\n",
        "\n",
        "Instrucciones:\n",
        "\n",
        "Subir el archivo preguntas_respuestas_unicuces.csv."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "WIii_iMZBuFS",
        "outputId": "dd8f174b-863d-4789-8145-c41cab05bc65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: transformers in /usr/local/lib/python3.10/dist-packages (4.44.2)\n",
            "Requirement already satisfied: faiss-gpu in /usr/local/lib/python3.10/dist-packages (1.7.2)\n",
            "Requirement already satisfied: datasets in /usr/local/lib/python3.10/dist-packages (3.0.1)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from transformers) (3.16.1)\n",
            "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.24.7)\n",
            "Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (1.26.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from transformers) (24.1)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (6.0.2)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.10/dist-packages (from transformers) (2024.9.11)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from transformers) (2.32.3)\n",
            "Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.4.5)\n",
            "Requirement already satisfied: tokenizers<0.20,>=0.19 in /usr/local/lib/python3.10/dist-packages (from transformers) (0.19.1)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.10/dist-packages (from transformers) (4.66.5)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (16.1.0)\n",
            "Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from datasets) (0.3.8)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from datasets) (2.2.2)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.10/dist-packages (from datasets) (3.5.0)\n",
            "Requirement already satisfied: multiprocess in /usr/local/lib/python3.10/dist-packages (from datasets) (0.70.16)\n",
            "Requirement already satisfied: fsspec<=2024.6.1,>=2023.1.0 in /usr/local/lib/python3.10/dist-packages (from fsspec[http]<=2024.6.1,>=2023.1.0->datasets) (2024.6.1)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.10/dist-packages (from datasets) (3.10.10)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (2.4.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (24.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (6.1.0)\n",
            "Requirement already satisfied: yarl<2.0,>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (1.15.2)\n",
            "Requirement already satisfied: async-timeout<5.0,>=4.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp->datasets) (4.0.3)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.10/dist-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.4.0)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2.2.3)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests->transformers) (2024.8.30)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.10/dist-packages (from pandas->datasets) (2024.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.16.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.10/dist-packages (from yarl<2.0,>=1.12.0->aiohttp->datasets) (0.2.0)\n"
          ]
        }
      ],
      "source": [
        "!pip install transformers faiss-gpu datasets"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "8Ap0r9l1gjTX",
        "outputId": "18d01888-d9a4-428f-b204-2a042e08369c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: faiss-cpu in /usr/local/lib/python3.10/dist-packages (1.9.0)\n",
            "Requirement already satisfied: numpy<3.0,>=1.25.0 in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from faiss-cpu) (24.1)\n",
            "Requirement already satisfied: flask-cors in /usr/local/lib/python3.10/dist-packages (5.0.0)\n",
            "Requirement already satisfied: Flask>=0.9 in /usr/local/lib/python3.10/dist-packages (from flask-cors) (2.2.5)\n",
            "Requirement already satisfied: Werkzeug>=2.2.2 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (3.0.4)\n",
            "Requirement already satisfied: Jinja2>=3.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (3.1.4)\n",
            "Requirement already satisfied: itsdangerous>=2.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (2.2.0)\n",
            "Requirement already satisfied: click>=8.0 in /usr/local/lib/python3.10/dist-packages (from Flask>=0.9->flask-cors) (8.1.7)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2>=3.0->Flask>=0.9->flask-cors) (3.0.1)\n",
            "Requirement already satisfied: pyngrok in /usr/local/lib/python3.10/dist-packages (7.2.0)\n",
            "Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.10/dist-packages (from pyngrok) (6.0.2)\n",
            "El servidor Flask está disponible en: NgrokTunnel: \"https://6895-34-23-32-231.ngrok-free.app\" -> \"http://localhost:5000\"\n",
            " * Serving Flask app '__main__'\n",
            " * Debug mode: off\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Instalar dependencias\n",
        "!pip install faiss-cpu\n",
        "!pip install flask-cors\n",
        "!pip install pyngrok\n",
        "\n",
        "from flask_cors import CORS\n",
        "import threading\n",
        "import os\n",
        "import pandas as pd\n",
        "from flask import Flask, request, jsonify\n",
        "import faiss\n",
        "import numpy as np\n",
        "from transformers import AutoTokenizer, AutoModel\n",
        "from pyngrok import ngrok\n",
        "\n",
        "# Inicializar Flask\n",
        "app = Flask(__name__)\n",
        "CORS(app)  # Habilitar CORS para evitar restricciones de origen cruzado\n",
        "\n",
        "# Definir el diccionario de preguntas y respuestas (FAQ)\n",
        "faq_dict = {\n",
        "    \"¿Qué es la inteligencia artificial?\": \"La inteligencia artificial (IA) es una rama de la informática que se centra en la creación de sistemas capaces de realizar tareas que normalmente requieren inteligencia humana.\",\n",
        "    \"¿Qué es el aprendizaje supervisado?\": \"El aprendizaje supervisado es un tipo de algoritmo de IA que se entrena con datos etiquetados, donde el modelo aprende a predecir una salida a partir de las entradas.\",\n",
        "    \"¿Cuál es la diferencia entre aprendizaje supervisado y no supervisado?\": \"El aprendizaje supervisado utiliza datos etiquetados para entrenar un modelo, mientras que el aprendizaje no supervisado trabaja con datos no etiquetados para encontrar patrones o agrupaciones.\",\n",
        "    \"¿Qué es un modelo de redes neuronales?\": \"Una red neuronal es un conjunto de algoritmos diseñados para reconocer patrones y se basa en la estructura y funcionamiento del cerebro humano.\",\n",
        "    \"¿Qué es el procesamiento del lenguaje natural (NLP)?\": \"El procesamiento del lenguaje natural es una rama de la IA que se centra en la interacción entre las computadoras y el lenguaje humano, como la comprensión de texto o el reconocimiento de voz.\",\n",
        "    \"¿Cómo funciona el aprendizaje por refuerzo?\": \"El aprendizaje por refuerzo se basa en un agente que toma acciones en un entorno y recibe recompensas o castigos. El objetivo es maximizar las recompensas a lo largo del tiempo.\",\n",
        "    \"¿Qué es RAG en inteligencia artificial?\": \"RAG (Retrieval-Augmented Generation) es un enfoque que combina la generación de texto con la recuperación de información relevante para proporcionar respuestas más precisas y actualizadas.\",\n",
        "    \"¿En qué consiste el machine learning?\": \"El machine learning es un subcampo de la IA que permite a las máquinas aprender a partir de los datos sin ser explícitamente programadas para realizar una tarea.\",\n",
        "    \"¿Qué es un chatbot generativo?\": \"Un chatbot generativo es un modelo de IA que genera respuestas en función de patrones aprendidos de grandes conjuntos de datos sin depender de información externa.\",\n",
        "    \"¿Cuál es la diferencia entre RAG y un chatbot generativo simple?\": \"RAG combina la generación de respuestas con la recuperación de información externa, mientras que un chatbot generativo simple solo usa la información almacenada en su modelo entrenado.\"\n",
        "}\n",
        "\n",
        "# Preparar el modelo y tokenizer de Hugging Face\n",
        "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "model = AutoModel.from_pretrained('sentence-transformers/all-MiniLM-L6-v2')\n",
        "\n",
        "# Función para codificar texto usando el modelo preentrenado\n",
        "def embed_text(texts):\n",
        "    inputs = tokenizer(texts, return_tensors='pt', padding=True, truncation=True)\n",
        "    embeddings = model(**inputs).last_hidden_state.mean(dim=1).detach().numpy()\n",
        "    return embeddings\n",
        "\n",
        "# Codificar todas las preguntas\n",
        "preguntas = list(faq_dict.keys())\n",
        "embeddings = embed_text(preguntas)\n",
        "\n",
        "# Crear el índice FAISS para realizar búsquedas de similitud\n",
        "index = faiss.IndexFlatL2(embeddings.shape[1])\n",
        "index.add(embeddings)\n",
        "\n",
        "# Configuración de ngrok (mantén seguro tu token)\n",
        "ngrok.set_auth_token('2nlzBKSP5BmoGB6eCEo93TDLSwg_4aWxdMjoN1p1k6uj7Gg71')\n",
        "\n",
        "# Ruta API para recibir las consultas y devolver las respuestas\n",
        "@app.route('/chatbot', methods=['POST'])\n",
        "def chatbot_api():\n",
        "    data = request.get_json()  # Recibe el JSON con la consulta\n",
        "    consulta = data.get('consulta', '')  # Extraer el texto de la consulta\n",
        "\n",
        "    # Verifica que el campo 'consulta' esté en el JSON\n",
        "    if not data or 'consulta' not in data:\n",
        "        return jsonify({\"error\": \"Solicitud incorrecta, falta el campo 'consulta'\"}), 400\n",
        "\n",
        "    # Codificar la consulta y buscar la pregunta más cercana\n",
        "    consulta_embedding = embed_text([consulta])\n",
        "    D, I = index.search(consulta_embedding, k=1)\n",
        "    pregunta_cercana = preguntas[I[0][0]]\n",
        "    respuesta = faq_dict[pregunta_cercana]\n",
        "    # Devolver la respuesta en formato JSON\n",
        "    return jsonify({'respuesta': respuesta})\n",
        "\n",
        "# Función para ejecutar el servidor Flask\n",
        "def run_flask():\n",
        "    app.run()\n",
        "\n",
        "# Crear el túnel ngrok y obtener la URL pública\n",
        "public_url = ngrok.connect(5000)\n",
        "print(f\"El servidor Flask está disponible en: {public_url}\")\n",
        "\n",
        "# Iniciar el servidor Flask en un hilo aparte para no bloquear el Colab\n",
        "thread = threading.Thread(target=run_flask)\n",
        "thread.start()\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ti6f0Yf49i1n"
      },
      "source": [
        "Identifica una mejora a tu chatbo e implementala\n",
        "\n",
        "Por ejemplo interfaz con Streamlimit, o telegram\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true
        },
        "id": "Vzngy5NgTu2F",
        "collapsed": true,
        "outputId": "d37a446a-2364-4049-98a4-a091a60fcbce"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "INFO:werkzeug:127.0.0.1 - - [22/Oct/2024 05:29:44] \"\u001b[33mPOST /chatbot HTTP/1.1\u001b[0m\" 404 -\n"
          ]
        },
        {
          "ename": "JSONDecodeError",
          "evalue": "Expecting value: line 1 column 1 (char 0)",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    973\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 974\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mcomplexjson\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    975\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mJSONDecodeError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/__init__.py\u001b[0m in \u001b[0;36mloads\u001b[0;34m(s, cls, object_hook, parse_float, parse_int, parse_constant, object_pairs_hook, **kw)\u001b[0m\n\u001b[1;32m    345\u001b[0m             parse_constant is None and object_pairs_hook is None and not kw):\n\u001b[0;32m--> 346\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_default_decoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    347\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(self, s, _w)\u001b[0m\n\u001b[1;32m    336\u001b[0m         \"\"\"\n\u001b[0;32m--> 337\u001b[0;31m         \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mraw_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    338\u001b[0m         \u001b[0mend\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/json/decoder.py\u001b[0m in \u001b[0;36mraw_decode\u001b[0;34m(self, s, idx)\u001b[0m\n\u001b[1;32m    354\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mStopIteration\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 355\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Expecting value\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merr\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    356\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mend\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m                           Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-88671ca1f2d5>\u001b[0m in \u001b[0;36m<cell line: 7>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrequests\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpost\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0murl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mjson\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresponse\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjson\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/requests/models.py\u001b[0m in \u001b[0;36mjson\u001b[0;34m(self, **kwargs)\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;31m# Catch JSON-related errors and raise as requests.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    977\u001b[0m             \u001b[0;31m# This aliases json.JSONDecodeError and simplejson.JSONDecodeError\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 978\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mRequestsJSONDecodeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdoc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    979\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    980\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mJSONDecodeError\u001b[0m: Expecting value: line 1 column 1 (char 0)"
          ]
        }
      ],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}